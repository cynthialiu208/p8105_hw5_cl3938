---
title: "Homework 5: Iteration"
author: "Cynthia Liu (cl3938)"
date: "11/18/2020"
output: github_document
---

```{r setup, include = FALSE}
library(tidyverse)
knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)
theme_set(theme_minimal() + theme(legend.position = "bottom"))
options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)
scale_colour_discrete = scale_colour_viridis_d()
scale_fill_discrete = scale_fill_viridis_d()
```

## Problem 1

Read in & clean the data.

```{r}
homicide_df = 
  read_csv("./data/homicide-data.csv") %>% 
  mutate(
    city_state = str_c(city, state, sep = "_"),
    resolved = case_when(
      disposition == "Closed without arrest" ~ "unsolved",
      disposition == "Open/No arrest"        ~ "unsolved",
      disposition == "Closed by arrest"      ~ "solved",
    )
  ) %>% 
  select(city_state, resolved) %>%
  filter(city_state != "Tulsa_AL")
```

Let's look at this a bit

```{r}
aggregate_df = 
  homicide_df %>% 
  group_by(city_state) %>% 
  summarize(
    hom_total = n(),
    hom_unsolved = sum(resolved == "unsolved")
  )
```

Can I do a prop test for a single city?

```{r}
prop.test(
  aggregate_df %>% filter(city_state == "Baltimore_MD") %>% pull(hom_unsolved), 
  aggregate_df %>% filter(city_state == "Baltimore_MD") %>% pull(hom_total)) %>% 
  broom::tidy()
```

Try to iterate ........

```{r}
results_df = 
  aggregate_df %>% 
  mutate(
    prop_tests = map2(.x = hom_unsolved, .y = hom_total, ~prop.test(x = .x, n = .y)),
    tidy_tests = map(.x = prop_tests, ~broom::tidy(.x))
  ) %>% 
  select(-prop_tests) %>% 
  unnest(tidy_tests) %>% 
  select(city_state, estimate, conf.low, conf.high)
```



```{r}
results_df %>% 
  mutate(city_state = fct_reorder(city_state, estimate)) %>% 
  ggplot(aes(x = city_state, y = estimate)) +
  geom_point() + 
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high)) + 
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))
```



```{r, error = TRUE}

homicide_df = 
  read_csv("data/homicide-data.csv") %>% 
  mutate(
    city_state = str_c(city, state, sep = "_"),
    resolved = case_when(
      disposition == "Closed without arrest" ~ "unsolved",
      disposition == "Open/No arrest"        ~ "unsolved",
      disposition == "Closed by arrest"      ~ "solved",
    )
  ) %>% 
  select(city_state, resolved) %>% 
  filter(city_state != "Tulsa_AL") %>% 
  nest(data = resolved)
```

## Problem 2 

data = map(.x = path_df$path, ~read_csv(.x)))

**Read in files and create raw dataframe:**
```{r, message = FALSE}
loc = "./data/trial-data/"
path_df = 
  tibble(
    path = list.files(loc),
  ) %>%
  mutate(
    path = str_c("./data/trial-data/", path),
    data = map(.x = path, ~read_csv(.x))
  ) %>%
  unnest(data)
```

**Clean raw dataset:**
```{r message = FALSE}
trial_df = path_df %>%
  mutate(path = map(.x = path, ~str_extract(.x, "(?<=./data/trial-data/).*(?=.csv)"))) %>%
  separate(path, c("treatment_arm", "patient_id"), sep = "_") %>%
  mutate(treatment_arm = ifelse(treatment_arm == "con", "control", "experimental")) %>%
  pivot_longer(
    cols = starts_with("week"),
    names_to = "week",
    names_prefix = "week_",
    values_to = "observation"
  ) 
```

**Spaghetti plot of subject observations over time, grouped by study treatment arm:**
```{r}
trial_df %>% 
  ggplot(aes(x = week, y = observation)) +
  geom_path(aes(group = patient_id, color = treatment_arm)) +
  labs(
    title = "Treatment Response by Study Arm",
    x = "Week",
    y = "Observation"
  ) + scale_color_lancet()
```

The plot shows clear differences between the control and experimental group over time. At study onset, both groups are indistinguishable in terms of measurements. However, as time progresses, observations of the experimental group become, on average, higher than those for the control group. At week 8, the two groups are completely separate. For the control group, measurement variation within the group seems to decrease over time, with the possibility of decreasing average measurement. This seems to suggest that the experimental treatment is effective, though it's unclear what it does and whether or not it's the intended purpose.

## Problem 3

Let's explore power in a two-sided one-sample t-test:

**Generating simulation data:**
```{r}
#fixed parameters
sample_size = 30
sigma = 5
mu_min = 0
mu_max = 6

#function to simulate single t-test
sim_t_test = function(mu) {
  
  sim_data = tibble(
    x = rnorm(n = sample_size, mean = mu, sd = sigma),
  )
  
  output = t.test(sim_data, mu = 0, conf.level = 0.95) %>%
  broom::tidy() %>%
  select(estimate, p.value)
}

#function to simulate multiple t-tests and calculate desired values
multiple_sim_prop = function(mu) {
  
  results =
    rerun(5000, sim_t_test(mu)) %>% 
    bind_rows() %>%
    summarize(
      mean_mu = mean(estimate),
      mean_rej_mu = mean(estimate[p.value <= 0.05]),
      count_rej = sum(p.value <= 0.05),
      prop_rej = count_rej/ n()
    )
  results
}

#run simulation for means from 0-6
test_output = 
  tibble(mu = 0:6) %>%
  mutate(values = map(.x = mu, ~multiple_sim_prop(.x))) %>%
  unnest(values)
```

**Plot showing relationship between effect size and power:**
```{r}
test_output %>%
  ggplot(aes(x = mu, y = prop_rej, fill = mu)) +
  geom_bar(stat = 'identity') +
  geom_smooth(se = F) +
  labs(
    title = "Relationship between effect size and power",
    x = "Effect Size (Mu)",
    y = "Power",
    caption = "Data generated from 5000 t-test simulations under the null hypothesis mu = 0") + 
  theme(legend.position = "none")
  
```
The plot shows that as effect size increases, so does power. The relationship is almost exponential, but difficult to tell as the it flattens as power approaches 1. At an effect size of 4 or greater, power is roughly 1. 

**Two-panel plot showing relationship between true and estimated mu**

```{r}


```
